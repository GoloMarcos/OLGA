{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InFBqe9B2kjN"
      },
      "source": [
        "# Train and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ud9784xY-tpB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.svm import OneClassSVM as OCSVM\n",
        "\n",
        "def define_gammas():\n",
        "  gammas = ['scale', 'auto']\n",
        "  return gammas\n",
        "\n",
        "def define_nus():\n",
        "  nus = []\n",
        "  for n in range(5,90,5):\n",
        "    nus.append(n/100)\n",
        "  for n in range(5,90,5):\n",
        "    nus.append(n/1000)\n",
        "\n",
        "  return nus\n",
        "\n",
        "def define_kernels():\n",
        "  return ['rbf', 'sigmoid','linear', 'poly']\n",
        "\n",
        "def evaluation_one_class(preds_interest, preds_outliers):\n",
        "    y_true = [1] * len(preds_interest) + [-1] * len(preds_outliers)\n",
        "    y_pred = list(preds_interest) + list(preds_outliers)\n",
        "    return classification_report(y_true, y_pred, output_dict=True)\n",
        "\n",
        "def evaluate_model(X_train, X_test, X_outlier, model):\n",
        "\n",
        "    one_class_classifier = model.fit(X_train)\n",
        "\n",
        "    Y_pred_interest = one_class_classifier.predict(X_test)\n",
        "\n",
        "    Y_pred_ruido = one_class_classifier.predict(X_outlier)\n",
        "\n",
        "    y_true = np.array([1] * len(X_test) + [-1] * len(X_outlier))\n",
        "\n",
        "    dic = evaluation_one_class(Y_pred_interest, Y_pred_ruido)\n",
        "\n",
        "    return dic\n",
        "\n",
        "def init_metrics():\n",
        "    metrics = {\n",
        "        '1': {\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1-score': []\n",
        "        },\n",
        "        '-1': {\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1-score': []\n",
        "        },\n",
        "        'macro avg': {\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1-score': []\n",
        "        },\n",
        "        'weighted avg': {\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1-score': []\n",
        "        },\n",
        "        'accuracy': [],\n",
        "        'time': []\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def save_values(metrics, values):\n",
        "    for key in metrics.keys():\n",
        "      if key == 'accuracy' or key == 'time':\n",
        "        metrics[key].append(values[key])\n",
        "      else:\n",
        "        for key2 in metrics[key].keys():\n",
        "          metrics[key][key2].append(values[key][key2])\n",
        "\n",
        "\n",
        "def extract_emb_from_graph(graph, representation_name):\n",
        "\n",
        "  x_train, x_int_val, x_nint_val, x_int_test, x_nint_test = [],[],[],[],[]\n",
        "\n",
        "  for node in graph.nodes():\n",
        "    if graph.nodes[node]['train'] == 1:\n",
        "      x_train.append(graph.nodes[node][representation_name])\n",
        "    elif graph.nodes[node]['val'] == 1 and graph.nodes[node]['label'] == 1:\n",
        "      x_int_val.append(graph.nodes[node][representation_name])\n",
        "    elif graph.nodes[node]['val'] == 1 and graph.nodes[node]['label'] == 0:\n",
        "      x_nint_val.append(graph.nodes[node][representation_name])\n",
        "    elif graph.nodes[node]['test'] == 1 and graph.nodes[node]['label'] == 1:\n",
        "      x_int_test.append(graph.nodes[node][representation_name])\n",
        "    elif graph.nodes[node]['test'] == 1 and graph.nodes[node]['label'] == 0:\n",
        "      x_nint_test.append(graph.nodes[node][representation_name])\n",
        "\n",
        "  return x_train, x_int_val, x_nint_val, x_int_test, x_nint_test\n",
        "\n",
        "def evaluate_models(l_graphs, representation_name, path, fn):\n",
        "\n",
        "    file_name = fn + representation_name + '_OCSVM.csv'\n",
        "\n",
        "    for kernel in define_kernels():\n",
        "      for gamma in define_gammas():\n",
        "        for nu in define_nus():\n",
        "          ocsvm = OCSVM(kernel=kernel,nu=nu,gamma=gamma,max_iter=500)\n",
        "          line_parameters =  'kernel:' + kernel + '_gamma:' + gamma + '_nu:' + str(nu)\n",
        "          metrics = init_metrics()\n",
        "\n",
        "          for graph in l_graphs:\n",
        "\n",
        "            x_train,x_int_val,x_nint_val,x_int_test,x_nint_test = extract_emb_from_graph(graph, representation_name)\n",
        "\n",
        "            start = time.time()\n",
        "            values = evaluate_model(x_train, x_int_val, x_nint_val, ocsvm)\n",
        "            end = time.time()\n",
        "            time_ = end - start\n",
        "            values['time'] = time_\n",
        "            save_values(metrics, values)\n",
        "\n",
        "          write_results(metrics, file_name, line_parameters, path)\n",
        "\n",
        "\n",
        "def write_results(metrics, file_name, line_parameters, path):\n",
        "    if not Path(path + file_name).is_file():\n",
        "        file_ = open(path + file_name, 'w')\n",
        "        string = 'Parameters'\n",
        "        for key in metrics.keys():\n",
        "            if key == 'accuracy' or key == 'time':\n",
        "              string += ';' + key + '-mean;' + key + '-std'\n",
        "            else:\n",
        "              for key2 in metrics[key].keys():\n",
        "                string += ';' + key + '_' + key2 + '-mean;' + key + '_' + key2 + '-std'\n",
        "\n",
        "        string += '\\n'\n",
        "        file_.write(string)\n",
        "        file_.close()\n",
        "\n",
        "    file_ = open(path + file_name, 'a')\n",
        "    string = line_parameters\n",
        "\n",
        "    for key in metrics.keys():\n",
        "      if key == 'accuracy' or key == 'time':\n",
        "        string += ';' + str(np.mean(metrics[key])) + ';' + str(np.std(metrics[key]))\n",
        "      else:\n",
        "        for key2 in metrics[key].keys():\n",
        "          string += ';' + str(np.mean(metrics[key][key2])) + ';' + str(np.std(metrics[key][key2]))\n",
        "\n",
        "    string += '\\n'\n",
        "    file_.write(string)\n",
        "    file_.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sNinuYz-9c95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no dataset: TUANDROMD\n",
            "no k: k=1\n",
            "com rep: features\n",
            "no dataset: musk\n",
            "no k: k=1\n",
            "com rep: features\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pt = '../../datasets/'\n",
        "\n",
        "basepath = Path(pt)\n",
        "\n",
        "path_results = '../../results_validation/'\n",
        "\n",
        "datasets = basepath.iterdir()\n",
        "\n",
        "for dataset in ['TUANDROMD', 'musk']: #', fakenews', 'terrorism','relevant_reviews', 'food', 'strawberry','pneumonia', 'musk', 'TUANDROMD'] \n",
        "  print('no dataset: ' + dataset)\n",
        "  for k in ['k=1']:#, 'k=2', 'k=3']:\n",
        "    print('no k: ' + k)\n",
        "    l_graphs = []\n",
        "    for fold in range(10):\n",
        "      path = pt + dataset + '/' + k + '/' + dataset + '_' + k + '_fold=' + str(fold) + '.gpickle'\n",
        "\n",
        "      graph = nx.read_gpickle(path)\n",
        "      l_graphs.append(graph)\n",
        "\n",
        "    for rep_initial in ['features']: #['features_node2vec', 'features_deepwalk', 'features_gae','features_node2vec_3', 'features_deepwalk_3', 'features_gae_3', 'features_gae_2', 'features_deepwalk_2', 'features_node2vec_2']\n",
        "\n",
        "      print('com rep: ' + rep_initial)\n",
        "      evaluate_models(l_graphs, rep_initial, path_results, dataset + '_' + k + '_')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN6JP7Bu2oxl"
      },
      "source": [
        "# Test Graph Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPa_ynNN2xit"
      },
      "outputs": [],
      "source": [
        "path_results = '../../results_validation/'\n",
        "\n",
        "path_results_test = '../../results_test/'\n",
        "\n",
        "pt = '../../datasets/'\n",
        "\n",
        "basepath = Path(path_results)\n",
        "datasets = basepath.iterdir()\n",
        "\n",
        "for dataset in datasets:\n",
        "  dataset = dataset.name\n",
        "  print('Dataset: ' + dataset)\n",
        "  basepath2 = Path(path_results + dataset)\n",
        "  ks = basepath2.iterdir()\n",
        "\n",
        "  for k in ks:\n",
        "    k = k.name\n",
        "    print('K: ' + k)\n",
        "    basepath3 = Path(path_results + dataset + '/' + k)\n",
        "    methods = basepath3.iterdir()\n",
        "\n",
        "    l_graphs = []\n",
        "    for fold in range(10):\n",
        "      path = pt + dataset + '/' + k + '/' + dataset + '_' + k + '_fold=' + str(fold) + '.gpickle'\n",
        "\n",
        "      graph = nx.read_gpickle(path)\n",
        "      l_graphs.append(graph)\n",
        "\n",
        "    pr = path_results_test + dataset + '_' + k + '_'\n",
        "\n",
        "    for method in methods:\n",
        "      if method.is_file() and method.name.split('-')[0] != 'OC':\n",
        "\n",
        "        method = method.name\n",
        "        df = pd.read_csv(path_results + dataset + '_' + k + '_' + method, sep=';')\n",
        "\n",
        "        best_f1 = max(df['macro avg_f1-score-mean'])\n",
        "\n",
        "        parameters = df[df['macro avg_f1-score-mean'] == best_f1]['Parameters'].iloc[0]\n",
        "\n",
        "        parts = parameters.split('_')\n",
        "\n",
        "        kernel = parts[0].split(':')[1]\n",
        "\n",
        "        gamma = parts[1].split(':')[1]\n",
        "\n",
        "        nu = float(parts[2].split(':')[1])\n",
        "\n",
        "        ocsvm = OCSVM(kernel=kernel,nu=nu,gamma=gamma)\n",
        "        line_parameters =  'kernel:' + kernel + '_gamma:' + gamma + '_nu:' + str(nu)\n",
        "        metrics = init_metrics()\n",
        "\n",
        "        for graph in l_graphs:\n",
        "\n",
        "          x_train, x_int_val, _, x_int_test, x_nint_test = extract_emb_from_graph(graph, method.replace('_OCSVM.csv', ''))\n",
        "\n",
        "          x_train = np.concatenate([x_train,x_int_val])\n",
        "\n",
        "          start = time.time()\n",
        "          values = evaluate_model(x_train, x_int_test, x_nint_test, ocsvm)\n",
        "          end = time.time()\n",
        "          time_ = end - start\n",
        "          values['time'] = time_\n",
        "          save_values(metrics, values)\n",
        "\n",
        "        write_results(metrics, method, line_parameters, pr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "path_results = '../../results_validation/'\n",
        "\n",
        "path_results_test = '../../results_test/'\n",
        "\n",
        "pt = '../../datasets/'\n",
        "\n",
        "basepath = Path(path_results)\n",
        "files = basepath.iterdir()\n",
        "\n",
        "for _file in files:\n",
        "  if os.path.isfile(_file):\n",
        "    \n",
        "    dataset = _file.name.split('_')[0]\n",
        "    if dataset == 'relevant':\n",
        "      dataset = 'relevant_reviews'\n",
        "\n",
        "    l_graphs = []\n",
        "    for fold in range(10):\n",
        "      path = pt + dataset + '/k=1/' + dataset + '_k=1_fold=' + str(fold) + '.gpickle'\n",
        "\n",
        "      graph = nx.read_gpickle(path)\n",
        "      l_graphs.append(graph)\n",
        "\n",
        "    pr = path_results_test + dataset + '_k=1_'\n",
        "\n",
        "    df = pd.read_csv(path_results + _file.name, sep=';')\n",
        "\n",
        "    best_f1 = max(df['macro avg_f1-score-mean'])\n",
        "\n",
        "    parameters = df[df['macro avg_f1-score-mean'] == best_f1]['Parameters'].iloc[0]\n",
        "\n",
        "    parts = parameters.split('_')\n",
        "\n",
        "    kernel = parts[0].split(':')[1]\n",
        "\n",
        "    gamma = parts[1].split(':')[1]\n",
        "\n",
        "    nu = float(parts[2].split(':')[1])\n",
        "\n",
        "    ocsvm = OCSVM(kernel=kernel,nu=nu,gamma=gamma, max_iter=500)\n",
        "    line_parameters =  'kernel:' + kernel + '_gamma:' + gamma + '_nu:' + str(nu)\n",
        "    metrics = init_metrics()\n",
        "\n",
        "    for graph in l_graphs:\n",
        "\n",
        "      x_train, x_int_val, _, x_int_test, x_nint_test = extract_emb_from_graph(graph, 'features')\n",
        "\n",
        "      x_train = np.concatenate([x_train,x_int_val])\n",
        "\n",
        "      start = time.time()\n",
        "      values = evaluate_model(x_train, x_int_test, x_nint_test, ocsvm)\n",
        "      end = time.time()\n",
        "      time_ = end - start\n",
        "      values['time'] = time_\n",
        "      save_values(metrics, values)\n",
        "\n",
        "    write_results(metrics, 'features_OCSVM', line_parameters, pr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "../../results_test/musk_k=1_features_OCSVM\n",
            "0.7180937485042478\n",
            "../../results_test/terrorism_k=1_features_OCSVM\n",
            "0.989205920866271\n",
            "../../results_test/pneumonia_k=1_features_OCSVM\n",
            "0.6525619063318506\n",
            "../../results_test/fakenews_k=1_features_OCSVM\n",
            "0.9106878935542136\n",
            "../../results_test/relevant_reviews_k=1_features_OCSVM\n",
            "0.5974299456811561\n",
            "../../results_test/TUANDROMD_k=1_features_OCSVM\n",
            "0.8811169488227575\n",
            "../../results_test/strawberry_k=1_features_OCSVM\n",
            "0.5765123008411216\n",
            "../../results_test/food_k=1_features_OCSVM\n",
            "0.9874305031542708\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "path_results_test = '../../results_test/'\n",
        "\n",
        "basepath = Path(path_results_test)\n",
        "files = basepath.iterdir()\n",
        "\n",
        "for _file in files:\n",
        "  if os.path.isfile(_file):\n",
        "    print(_file)\n",
        "    df = pd.read_csv(path_results_test + _file.name, sep=';')\n",
        "\n",
        "    best_f1 = max(df['macro avg_f1-score-mean'])\n",
        "    print(best_f1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "olga_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
